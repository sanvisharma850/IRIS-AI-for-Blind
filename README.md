# IRIS – AI Assistive Device for the Visually Impaired
An AI-powered indoor navigation assistant for the visually impaired using YOLOv8, LiDAR, and Raspberry Pi.

IRIS is a smart indoor navigation device developed using YOLOv8 object detection and TF-Luna LiDAR sensor powered by Raspberry Pi 4. It converts real-time spatial data into audio cues to help visually impaired users navigate indoor spaces confidently.

## 🔍 Features
- Object Detection with YOLOv8
- Distance Measurement via LiDAR
- Real-time Audio Feedback using Google Text-to-Speech
- Tactile & Voice Controls
- Raspberry Pi 4 based prototype

## 📄 Project Report
See the full report: [IRIS_Capstone_Report.pdf]([./IRIS_Capstone_Report.pdf](https://drive.google.com/file/d/13kk_HCvFUWXpyt7_o0xfqgMa6JcmOddq/view?usp=drive_link))

## 📹 Project Video
Watch here: [IRIS Demo Video](https://www.youtube.com/watch?v=LRy-uAsT1LU)

## 👨‍💻 Team
- Sanvi Sharma – Project Leader & Designer
- Madhav Gupta – Coder & Data Expert
- Harshit Sachdeva – Researcher & Data Expert
- Amanjyot Singh – Researcher

## 🛠️ Tools Used
- YOLOv8
- TensorFlow / PyTorch
- OpenCV
- Google TTS API
- Raspberry Pi 4
- TF-Luna LiDAR

## 🔐 License
MIT License

---

### **4. Push to GitHub**

Inside the folder:

```bash
git init
git remote add origin https://github.com/your-username/IRIS-Assistive-AI.git
git add .
git commit -m "Initial commit - IRIS AI project"
git push -u origin master
