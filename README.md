# IRIS â€“ AI Assistive Device for the Visually Impaired
An AI-powered indoor navigation assistant for the visually impaired using YOLOv8, LiDAR, and Raspberry Pi.

IRIS is a smart indoor navigation device developed using YOLOv8 object detection and TF-Luna LiDAR sensor powered by Raspberry Pi 4. It converts real-time spatial data into audio cues to help visually impaired users navigate indoor spaces confidently.

## ğŸ” Features
- Object Detection with YOLOv8
- Distance Measurement via LiDAR
- Real-time Audio Feedback using Google Text-to-Speech
- Tactile & Voice Controls
- Raspberry Pi 4 based prototype

## ğŸ“„ Project Report
See the full report: [IRIS_Capstone_Report.pdf]([./IRIS_Capstone_Report.pdf](https://drive.google.com/file/d/13kk_HCvFUWXpyt7_o0xfqgMa6JcmOddq/view?usp=drive_link))

## ğŸ“¹ Project Video
Watch here: [IRIS Demo Video](https://www.youtube.com/watch?v=LRy-uAsT1LU)

## ğŸ‘¨â€ğŸ’» Team
- Sanvi Sharma â€“ Project Leader & Designer
- Madhav Gupta â€“ Coder & Data Expert
- Harshit Sachdeva â€“ Researcher & Data Expert
- Amanjyot Singh â€“ Researcher

## ğŸ› ï¸ Tools Used
- YOLOv8
- TensorFlow / PyTorch
- OpenCV
- Google TTS API
- Raspberry Pi 4
- TF-Luna LiDAR

## ğŸ” License
MIT License

---

### **4. Push to GitHub**

Inside the folder:

```bash
git init
git remote add origin https://github.com/your-username/IRIS-Assistive-AI.git
git add .
git commit -m "Initial commit - IRIS AI project"
git push -u origin master
